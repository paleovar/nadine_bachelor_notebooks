{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as ani\n",
    "from scipy.integrate import odeint\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotopes = Dataset('climatology/xnapa_isotopes.nc', \"a\")\n",
    "precipitation = Dataset('climatology/xnapa_precip.nc', \"a\")\n",
    "surface_temperature = Dataset('climatology/xnapa_temp.nc', \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = isotopes.variables[\"latitude\"][:].data[1:-1]\n",
    "long = isotopes.variables[\"longitude\"][:].data\n",
    "t = isotopes.variables[\"t\"][:].data\n",
    "\n",
    "trash = [626, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do18 = []\n",
    "precip = []\n",
    "temp = []\n",
    "for i in range(len(t)):\n",
    "    do18.append(isotopes.variables[\"dO18\"][i][0].data[1:-1].reshape(71*96))\n",
    "    precip.append(precipitation.variables[\"precip\"][i][0].data[1:-1].reshape(71*96))\n",
    "    temp.append(surface_temperature.variables[\"temp_1\"][i][0].data[1:-1].reshape(71*96))\n",
    "    \n",
    "do18 = pd.DataFrame(np.delete(np.delete(np.asarray(do18), 0, 0), 626, 0)[:1000])\n",
    "precip = pd.DataFrame(np.delete(np.delete(np.asarray(precip), 0, 0), 626, 0)[:1000])\n",
    "temp = pd.DataFrame(np.delete(np.delete(np.asarray(temp), 0, 0), 626, 0)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_1(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*(n_temp+n_precip), input_dim=n_temp+n_precip, activation='relu'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='relu'))\n",
    "    model.add(Dense(n_y, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, verbose=0, batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_2(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*(n_temp+n_precip), input_dim=n_temp+n_precip, activation='relu'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='relu'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='relu'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='relu'))\n",
    "    model.add(Dense(n_y, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, verbose=0, batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_3(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*(n_temp+n_precip), input_dim=n_temp+n_precip, activation='relu'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='relu'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='linear'))\n",
    "    model.add(Dense(2*(n_temp+n_precip), activation='linear'))\n",
    "    model.add(Dense(n_y, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, verbose=0, batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_4(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*(n_temp+n_precip), input_dim=n_temp+n_precip, activation='relu'))\n",
    "    model.add(Dense(3*(n_temp+n_precip), activation='relu'))\n",
    "    model.add(Dense(3*(n_temp+n_precip), activation='linear'))\n",
    "    model.add(Dense(n_y, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, verbose=0, batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_pca_test(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=1, epochs=50, batch_size=20, \n",
    "                 train_proportion=0.9, random=True):\n",
    "    \n",
    "    if random:\n",
    "        random_idx = np.random.permutation(do18.index.values)\n",
    "    \n",
    "        temp = temp.reindex(random_idx)\n",
    "        precip = precip.reindex(random_idx)\n",
    "        do18 = do18.reindex(random_idx)\n",
    "    \n",
    "    #devide training and test data\n",
    "    do18_train = do18[:int(np.floor(train_proportion*len(do18)))].reset_index(drop=True)\n",
    "    do18_test = do18[int(np.floor(train_proportion*len(do18))):].reset_index(drop=True)\n",
    "\n",
    "    temp_train = temp[:int(np.floor(train_proportion*len(temp)))].reset_index(drop=True)\n",
    "    temp_test = temp[int(np.floor(train_proportion*len(temp))):].reset_index(drop=True)\n",
    "\n",
    "    precip_train = precip[:int(np.floor(train_proportion*len(precip)))].reset_index(drop=True)\n",
    "    precip_test = precip[int(np.floor(train_proportion*len(precip))):].reset_index(drop=True)\n",
    "    \n",
    "    #define scalers\n",
    "    scaler_temp = StandardScaler().fit(temp)\n",
    "    scaler_precip = StandardScaler().fit(precip)\n",
    "    scaler_do18 = StandardScaler().fit(do18)\n",
    "    \n",
    "    #scale data\n",
    "    do18_train_scaler = scaler_do18.transform(do18_train)\n",
    "    do18_test_scaler = scaler_do18.transform(do18_test)\n",
    "\n",
    "    temp_train_scaler = scaler_temp.transform(temp_train)\n",
    "    temp_test_scaler = scaler_temp.transform(temp_test)\n",
    "\n",
    "    precip_train_scaler = scaler_precip.transform(precip_train)\n",
    "    precip_test_scaler = scaler_precip.transform(precip_test)\n",
    "    \n",
    "    #define pcas and fit data\n",
    "    pca_temp = PCA(n_components=n_temp).fit(np.append(temp_train_scaler, temp_test_scaler, axis=0))\n",
    "    pca_precip = PCA(n_components=n_precip).fit(np.append(precip_train_scaler, precip_test_scaler, axis=0))\n",
    "    pca_do18 = PCA(n_components=n_y).fit(np.append(do18_train_scaler, do18_test_scaler, axis=0))\n",
    "    \n",
    "    #transform data\n",
    "    do18_train_pc = pca_do18.transform(do18_train_scaler)\n",
    "    do18_test_pc = pca_do18.transform(do18_test_scaler)\n",
    "\n",
    "    temp_train_pc = pca_temp.transform(temp_train_scaler)\n",
    "    temp_test_pc = pca_temp.transform(temp_test_scaler)\n",
    "\n",
    "    precip_train_pc = pca_precip.transform(precip_train_scaler)\n",
    "    precip_test_pc = pca_precip.transform(precip_test_scaler)\n",
    "    \n",
    "    \n",
    "    X_train = np.append(temp_train_pc, precip_train_pc, axis=1)+100\n",
    "    X_test = np.append(temp_test_pc, precip_test_pc, axis=1)+100\n",
    "\n",
    "    Y_train = do18_train_pc+100\n",
    "    Y_test = do18_test_pc+100\n",
    "\n",
    "    Y = pd.DataFrame(np.append(Y_train, Y_test, axis=0))-100\n",
    "    \n",
    "    #####################################################################\n",
    "    #train model\n",
    "    if network==1:\n",
    "        model = network_1(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size)\n",
    "    elif network==2:\n",
    "        model = network_2(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size)\n",
    "    elif network==3:\n",
    "        model = network_3(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size)\n",
    "    elif network==4:\n",
    "        model = network_4(X_train, Y_train, X_test, Y_test, n_temp, n_precip, n_y, epochs, batch_size)\n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    #predict test data\n",
    "    pred_pc = pd.DataFrame(model.predict(X_test)-100)\n",
    "    pred_norm = pd.DataFrame(pca_do18.inverse_transform(pred_pc))\n",
    "    pred = pd.DataFrame(scaler_do18.inverse_transform(pred_norm))\n",
    "    \n",
    "    \n",
    "    #return pca and final data\n",
    "    return pred_pc, pred_norm, pred, do18_test_pc, pd.DataFrame(do18_test_scaler), do18_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=1, epochs=50, batch_size=20, runs=10,\n",
    "                 train_proportion=0.9, random=True):\n",
    "    \n",
    "    pred_pc, pred_norm, pred, Y_test, do18_test_scaler, do18_test = ann_pca_test(\n",
    "            temp, precip, do18, n_temp, n_precip, n_y, \n",
    "            network, epochs, batch_size, \n",
    "            train_proportion, random)\n",
    "    \n",
    "    pred_list = copy.deepcopy(pred)\n",
    "    test_list = copy.deepcopy(do18_test)\n",
    "    \n",
    "    for i in range(runs):\n",
    "        pred_pc, pred_norm, pred, Y_test, do18_test_scaler, do18_test = ann_pca_test(\n",
    "            temp, precip, do18, n_temp, n_precip, n_y, \n",
    "            network, epochs, batch_size, \n",
    "            train_proportion, random)\n",
    "        pred_list = pred_list.append(pred)\n",
    "        test_list = test_list.append(do18_test)\n",
    "    pred_list = pred_list.reset_index(drop=True)\n",
    "    test_list = test_list.reset_index(drop=True)\n",
    "    \n",
    "    rmse_geolist = []\n",
    "    for pixel in test_list.columns.values:\n",
    "        rmse_pixel = mean_squared_error(pred_list[pixel].values, test_list[pixel].values, squared=False)\n",
    "        rmse_geolist.append(rmse_pixel)\n",
    "    df_rmse_geolist = pd.DataFrame(np.asarray(rmse_geolist).reshape(71,96))\n",
    "    \n",
    "    return df_rmse_geolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.cos(np.deg2rad(lat))\n",
    "weights = weights/weights.sum()\n",
    "weights = weights[:, np.newaxis] * np.ones_like(do18.mean().values.reshape(71,96))\n",
    "\n",
    "def weighted_avg_std(values, weights):\n",
    "    average = np.average(values, weights=weights)\n",
    "    variance = (((values - average)**2)*weights).sum()/(weights.sum() - (weights**2).sum()/weights.sum())\n",
    "    return (average, math.sqrt(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=1, epochs=50, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 +- 0.95 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=1, epochs=200, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 +- 0.95 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=1, epochs=400, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 +- 0.97 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=50, \n",
    "                 network=1, epochs=200, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95 +- 1.00 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=50, \n",
    "                 network=1, epochs=400, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83 +- 0.94 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=50, \n",
    "                 network=1, epochs=400, batch_size=10, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87 +- 0.96 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=2, epochs=200, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93 +- 0.99 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=2, epochs=400, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 +- 0.95 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=2, epochs=200, batch_size=10, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 +- 0.96 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=3, epochs=200, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nadine/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "0.89 +- 0.97 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=3, epochs=200, batch_size=10, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89 +- 0.97 permil\n"
     ]
    }
   ],
   "source": [
    "df = test_network(temp, precip, do18, n_temp=20, n_precip=20, n_y=20, \n",
    "                 network=4, epochs=200, batch_size=20, runs=10)\n",
    "\n",
    "print(r\"{:.2f} +- {:.2f} permil\".format(weighted_avg_std(df.values, weights)[0], weighted_avg_std(df.values, weights)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
